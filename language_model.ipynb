{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "from itertools import product\n",
    "import math\n",
    "import nltk\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "SOS = \"<s> \"\n",
    "EOS = \"</s>\"\n",
    "UNK = \"<UNK>\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_sentence_tokens(sentences, n):\n",
    "    \n",
    "    sos = SOS * (n-1) if n > 1 else SOS\n",
    "    return ['{}{} {}'.format(sos, s, EOS) for s in sentences]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_singletons(tokens):\n",
    "    vocab = nltk.FreqDist(tokens)\n",
    "    return [token if vocab[token] > 1 else UNK for token in tokens]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(sentences, n):\n",
    "    sentences = add_sentence_tokens(sentences, n)\n",
    "    tokens = ' '.join(sentences).split(' ')\n",
    "    tokens = replace_singletons(tokens)\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(data_dir):\n",
    "    train_path = os.path.join(\n",
    "        data_dir, 'train.txt')  # data_dir.join('train.txt')\n",
    "    test_path = os.path.join(\n",
    "        data_dir, 'test.txt')  # data_dir.join('test.txt')\n",
    "\n",
    "    with open(train_path, 'r', encoding='utf-8') as f:\n",
    "        train = [l.strip() for l in f.readlines()]\n",
    "    with open(test_path, 'r', encoding='utf-8') as f:\n",
    "        test = [l.strip() for l in f.readlines()]\n",
    "    return train, test\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LanguageModel(object):\n",
    "\n",
    "    def __init__(self, train_data, n, laplace=1):\n",
    "        self.n = n\n",
    "        self.laplace = laplace\n",
    "        self.tokens = preprocess(train_data, n)\n",
    "        self.vocab = nltk.FreqDist(self.tokens)\n",
    "        self.model = self._create_model()\n",
    "        self.masks = list(reversed(list(product((0, 1), repeat=n))))\n",
    "\n",
    "    def _smooth(self):\n",
    "        \n",
    "        vocab_size = len(self.vocab)\n",
    "\n",
    "        n_grams = nltk.ngrams(self.tokens, self.n)\n",
    "        n_vocab = nltk.FreqDist(n_grams)\n",
    "\n",
    "        m_grams = nltk.ngrams(self.tokens, self.n-1)\n",
    "        m_vocab = nltk.FreqDist(m_grams)\n",
    "\n",
    "        def smoothed_count(n_gram, n_count):\n",
    "            m_gram = n_gram[:-1]\n",
    "            m_count = m_vocab[m_gram]\n",
    "            return (n_count + self.laplace) / (m_count + self.laplace * vocab_size)\n",
    "\n",
    "        return {n_gram: smoothed_count(n_gram, count) for n_gram, count in n_vocab.items()}\n",
    "\n",
    "    def _create_model(self):\n",
    "        \n",
    "        if self.n == 1:\n",
    "            num_tokens = len(self.tokens)\n",
    "            return {(unigram,): count / num_tokens for unigram, count in self.vocab.items()}\n",
    "        else:\n",
    "            return self._smooth()\n",
    "\n",
    "    def _convert_oov(self, ngram):\n",
    "        def mask(ngram, bitmask): return tuple(\n",
    "            (token if flag == 1 else \"<UNK>\" for token, flag in zip(ngram, bitmask)))\n",
    "\n",
    "        ngram = (ngram,) if type(ngram) is str else ngram\n",
    "        for possible_known in [mask(ngram, bitmask) for bitmask in self.masks]:\n",
    "            if possible_known in self.model:\n",
    "                return possible_known\n",
    "\n",
    "    def perplexity(self, test_data):\n",
    "        \n",
    "        test_tokens = preprocess(test_data, self.n)\n",
    "        test_ngrams = nltk.ngrams(test_tokens, self.n)\n",
    "        N = len(test_tokens)\n",
    "\n",
    "        known_ngrams = (self._convert_oov(ngram) for ngram in test_ngrams)\n",
    "        probabilities = [self.model[ngram] for ngram in known_ngrams]\n",
    "\n",
    "        return math.exp((-1/N) * sum(map(math.log, probabilities)))\n",
    "\n",
    "    def _best_candidate(self, prev, i, without=[]):\n",
    "        \n",
    "        blacklist = [\"<UNK>\"] + without\n",
    "        candidates = ((ngram[-1], prob) for ngram,\n",
    "                      prob in self.model.items() if ngram[:-1] == prev)\n",
    "        candidates = filter(\n",
    "            lambda candidate: candidate[0] not in blacklist, candidates)\n",
    "        candidates = sorted(\n",
    "            candidates, key=lambda candidate: candidate[1], reverse=True)\n",
    "        if len(candidates) == 0:\n",
    "            return (\"</s>\", 1)\n",
    "        else:\n",
    "            return candidates[0 if prev != () and prev[-1] != \"<s>\" else i]\n",
    "\n",
    "    def generate_sentences(self, num, min_len=12, max_len=24):\n",
    "\n",
    "        for i in range(num):\n",
    "            sent, prob = [\"<s>\"] * max(1, self.n-1), 1\n",
    "            while sent[-1] != \"</s>\":\n",
    "                prev = () if self.n == 1 else tuple(sent[-(self.n-1):])\n",
    "                blacklist = sent + ([\"</s>\"] if len(sent) < min_len else [])\n",
    "                next_token, next_prob = self._best_candidate(\n",
    "                    prev, i, without=blacklist)\n",
    "                sent.append(next_token)\n",
    "                prob *= next_prob\n",
    "\n",
    "                if len(sent) >= max_len:\n",
    "                    sent.append(\"</s>\")\n",
    "\n",
    "            yield ' '.join(sent), -1/math.log(prob)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1-gram model...\n",
      "Vocabulary size: 11646\n",
      "Generating sentences...\n",
      "<s> the to of and a that in I is we you </s> (0.02094)\n",
      "<s> to of and a that in I is we you And the it this was for are have with on -- they about </s> (0.00934)\n",
      "<s> of and a that in I is we you And it to this was for are have with on -- they about be </s> (0.00914)\n",
      "<s> and a that in I is we you And it this of was for are have with on -- they about be my </s> (0.00899)\n",
      "<s> a that in I is we you And it this was and for are have with on -- they about be my not </s> (0.00884)\n",
      "<s> that in I is we you And it this was for a are have with on -- they about be my not as </s> (0.00871)\n",
      "<s> in I is we you And it this was for are that have with on -- they about be my not as can </s> (0.00858)\n",
      "<s> I is we you And it this was for are have in with on -- they about be my not as can at </s> (0.00847)\n",
      "<s> is we you And it this was for are have with I on -- they about be my not as can at our </s> (0.00837)\n",
      "<s> we you And it this was for are have with on is -- they about be my not as can at our So </s> (0.00827)\n",
      "Model perplexity: 364.616\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#1-gram\n",
    "# Load and prepare train/test data\n",
    "data_path = r\"C:\\Users\\Bot\\PycharmProjects\\NLP\\data1\"\n",
    "train, test = load_data(data_path)\n",
    "\n",
    "print(\"{}-gram model...\".format(1))\n",
    "lm = LanguageModel(train, 1)\n",
    "print(\"Vocabulary size: {}\".format(len(lm.vocab)))\n",
    "\n",
    "print(\"Generating sentences...\")\n",
    "for sentence, prob in lm.generate_sentences(10):\n",
    "    print(\"{} ({:.5f})\".format(sentence, prob))\n",
    "\n",
    "perplexity = lm.perplexity(test)\n",
    "print(\"Model perplexity: {:.3f}\".format(perplexity))\n",
    "print(\"\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2-gram model...\n",
      "Vocabulary size: 11646\n",
      "Generating sentences...\n",
      "<s> And I was a lot of the world is that we can be able to do you </s> (0.01314)\n",
      "<s> So I was a lot of the world is that we can be able to do you </s> (0.01291)\n",
      "<s> I was a lot of the world is that we can be able to do you </s> (0.01372)\n",
      "<s> But I was a lot of the world is that we can be able to do you </s> (0.01279)\n",
      "<s> We have to the world is a lot of our own country </s> (0.01584)\n",
      "<s> The first time I was a lot of the world is that we can be able to do you </s> (0.01105)\n",
      "<s> \" And I was a lot of the world is that we can be able to do you </s> (0.01215)\n",
      "<s> It was a lot of the world is that we can be able to do you </s> (0.01338)\n",
      "<s> It's a lot of the world is that we can be able to do you </s> (0.01409)\n",
      "<s> They were the world is a lot of our own country </s> (0.01580)\n",
      "Model perplexity: 385.890\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#2-gram\n",
    "data_path = r\"C:\\Users\\Bot\\PycharmProjects\\NLP\\data1\"\n",
    "train, test = load_data(data_path)\n",
    "\n",
    "print(\"{}-gram model...\".format(2))\n",
    "lm = LanguageModel(train, 2)\n",
    "print(\"Vocabulary size: {}\".format(len(lm.vocab)))\n",
    "\n",
    "print(\"Generating sentences...\")\n",
    "for sentence, prob in lm.generate_sentences(10):\n",
    "    print(\"{} ({:.5f})\".format(sentence, prob))\n",
    "\n",
    "perplexity = lm.perplexity(test)\n",
    "print(\"Model perplexity: {:.3f}\".format(perplexity))\n",
    "print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3-gram model...\n",
      "Vocabulary size: 11646\n",
      "Generating sentences...\n",
      "<s> <s> And I think we need to do with the same </s> (0.01530)\n",
      "<s> <s> So I was a little bit of an entire year </s> (0.01387)\n",
      "<s> <s> I was a little bit of an entire year </s> (0.01738)\n",
      "<s> <s> But I think we need to do with the same </s> (0.01469)\n",
      "<s> <s> We have to be a better world for themselves and posting them under the surface of planets like Mars </s> (0.00659)\n",
      "<s> <s> The first time in a world where the sea level </s> (0.01305)\n",
      "<s> <s> \" And I think we need to do with the same </s> (0.01347)\n",
      "<s> <s> It was a little bit of an entire year </s> (0.01703)\n",
      "<s> <s> It's a very long time and energy to actually pay attention </s> (0.01103)\n",
      "<s> <s> They have a lot of people who are in the world </s> (0.01347)\n",
      "Model perplexity: 760.479\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#3-gram\n",
    "data_path = r\"C:\\Users\\Bot\\PycharmProjects\\NLP\\data1\"\n",
    "train, test = load_data(data_path)\n",
    "\n",
    "print(\"{}-gram model...\".format(3))\n",
    "lm = LanguageModel(train, 3)\n",
    "print(\"Vocabulary size: {}\".format(len(lm.vocab)))\n",
    "\n",
    "print(\"Generating sentences...\")\n",
    "for sentence, prob in lm.generate_sentences(10):\n",
    "    print(\"{} ({:.5f})\".format(sentence, prob))\n",
    "\n",
    "perplexity = lm.perplexity(test)\n",
    "print(\"Model perplexity: {:.3f}\".format(perplexity))\n",
    "print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2-gram model...\n",
      "Vocabulary size: 11646\n",
      "Generating sentences...\n",
      "<s> And I was a lot of the world is that we can be able to do you </s> (0.02363)\n",
      "<s> So I was a lot of the world is that we can be able to do you </s> (0.02327)\n",
      "<s> I was a lot of the world is that we can be able to do you </s> (0.02448)\n",
      "<s> But I was a lot of the world is that we can be able to do you </s> (0.02297)\n",
      "<s> We have to the world is a lot of our own country </s> (0.02895)\n",
      "<s> The first time I was a lot of the world is that we can be able to do you </s> (0.02047)\n",
      "<s> \" And I was a lot of the world is that we can be able to do you </s> (0.02201)\n",
      "<s> It was a lot of the world is that we can be able to do you </s> (0.02453)\n",
      "<s> It's a lot of the world is that we can be able to do you </s> (0.02571)\n",
      "<s> They were the world is a lot of our own country </s> (0.02923)\n",
      "Model perplexity: 37.851\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#2-gram with laplacing 0.0001\n",
    "data_path = r\"C:\\Users\\Bot\\PycharmProjects\\NLP\\data1\"\n",
    "train, test = load_data(data_path)\n",
    "\n",
    "print(\"{}-gram model...\".format(2))\n",
    "lm = LanguageModel(train, 2, laplace=0.0001)\n",
    "#lm = LanguageModel(train, 2)\n",
    "print(\"Vocabulary size: {}\".format(len(lm.vocab)))\n",
    "\n",
    "print(\"Generating sentences...\")\n",
    "for sentence, prob in lm.generate_sentences(10):\n",
    "    print(\"{} ({:.5f})\".format(sentence, prob))\n",
    "\n",
    "perplexity = lm.perplexity(test)\n",
    "print(\"Model perplexity: {:.3f}\".format(perplexity))\n",
    "print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
